{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre‐training via XGBoost for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\Python3.6\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, roc_auc_score, log_loss, ndcg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LON = '../data/LON-A/London_Attractions_Complete_Review.csv'\n",
    "DATASET_NYC = '../data/NYC-R/New_York_City_Restaurant_Complete_Review.csv'\n",
    "\n",
    "user_columns = ['uage', 'ugender', 'ucity', 'ucountry', 'uid_index', 'ulevel', 'ustyle']\n",
    "LON_item_columns = ['iid', 'iattribute', 'irating', 'itag']\n",
    "NYC_item_columns = ['iid', 'iattribute', 'iprice', 'irating', 'itag']\n",
    "rating_columns = ['rtime', 'rquote', 'rrate', 'rid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "LON_sparse_features = [\"uage\", \"ugender\", \"ucity\", \"ucountry\", \"uid_index\", \"ulevel\", 'iid', 'irating']\n",
    "NYC_sparse_features = [\"uage\", \"ugender\", \"ucity\", \"ucountry\", \"uid_index\", \"ulevel\", 'iid', 'irating', 'iprice']\n",
    "var_sparse_features = ['ustyle', 'iattribute', 'itag']\n",
    "\n",
    "def sort_by_time(df):\n",
    "    return df.sort_values(by=['rid'], ascending=True)\n",
    "\n",
    "def filter_by_occurrence(df, column, threshold):\n",
    "    return df.groupby(column).filter(lambda x: len(x) >= threshold)\n",
    "\n",
    "def split_df(df):\n",
    "    df['rating_cumcounts'] = df.groupby(['uid_index'])['rid'].rank(method='first', ascending=True)\n",
    "    tmp = df.groupby('uid_index').size().rename('total_counts')\n",
    "    df = df.join(tmp, on='uid_index', rsuffix='_r')\n",
    "    train_df = df.loc[df['rating_cumcounts'] < (df['total_counts']*0.8)]\n",
    "    test_df = df.loc[df['rating_cumcounts'] >= (df['total_counts']*0.8)]\n",
    "    train_df, validation_df = train_test_split(train_df, test_size=0.1, random_state=1)\n",
    "    \n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "def preprocessing(df):\n",
    "    df = sort_by_time(df)\n",
    "    df = filter_by_occurrence(df, 'uid_index', 5)\n",
    "    df = filter_by_occurrence(df, 'iid', 5)\n",
    "    df['rrate'] = df['rrate'].apply(lambda x: 1 if x != 'None' else 0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def get_data(DATASET = 'LON'):\n",
    "    assert DATASET in ['LON', 'NYC']\n",
    "    \n",
    "    print('Read data...')\n",
    "    if DATASET == 'LON':\n",
    "        df = pd.read_csv(DATASET_LON, sep='\\t')[user_columns + LON_item_columns + rating_columns].fillna('NaN')\n",
    "        sparse_features = LON_sparse_features\n",
    "    else:\n",
    "        df = pd.read_csv(DATASET_NYC, sep='\\t')[user_columns + NYC_item_columns + rating_columns].fillna('NaN')\n",
    "        sparse_features = NYC_sparse_features\n",
    "    \n",
    "    # sort, filter, binarize\n",
    "    df = preprocessing(df)\n",
    "    \n",
    "    #Label encode categorical features\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        df[feat] = lbe.fit_transform(df[feat].astype('str'))\n",
    "\n",
    "    train_df, val_df, test_df = split_df(df)      \n",
    "    \n",
    "    train_y, val_y, test_y = train_df[['rrate']], val_df[['rrate']], test_df[['rrate']]\n",
    "    \n",
    "    train_df, val_df, test_df = train_df[sparse_features], val_df[sparse_features], test_df[sparse_features]\n",
    "    \n",
    "    return train_df, val_df, test_df, train_y, val_y, test_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    " - user : uage, ugender, ucity, ucountry, uid_index, ulevel\n",
    " - item : iid, irating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data...\n",
      "\n",
      "train shape: \n",
      " (87440, 8)\n",
      "\n",
      "validation  shape: \n",
      " (9716, 8)\n",
      "\n",
      "test shape: \n",
      " (39339, 8)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df, train_y, val_y, test_y = get_data('LON')\n",
    "print(\"\\ntrain shape: \\n\",train_df.shape)\n",
    "print(\"\\nvalidation  shape: \\n\",val_df.shape)\n",
    "print(\"\\ntest shape: \\n\",test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB‐LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost val auc: 0.97092\n",
      "xgboost test auc: 0.95323\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(nthread=4,\n",
    "                          learning_rate=0.08,\n",
    "                          n_estimators=50,\n",
    "                          max_depth=5,\n",
    "                          gamma=0,\n",
    "                          subsample=0.9,\n",
    "                          colsample_bytree=0.5)\n",
    "\n",
    "\n",
    "model.fit(train_df.values, train_y.values.ravel())\n",
    "\n",
    "y_pred_val = model.predict_proba(val_df.values)\n",
    "y_pred_test = model.predict_proba(test_df.values)\n",
    "\n",
    "xgb_val_auc = roc_auc_score(np.array(val_y), np.array(y_pred_val)[:,1])\n",
    "xgb_test_auc = roc_auc_score(np.array(test_y), np.array(y_pred_test)[:,1])\n",
    "print('xgboost val auc: %.5f' % xgb_val_auc)\n",
    "print('xgboost test auc: %.5f' % xgb_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost encoding\n",
    "xgboost = model\n",
    "\n",
    "#apply()get leaf indices\n",
    "X_train_leaves = xgboost.apply(train_df.values)\n",
    "X_val_leaves = xgboost.apply(val_df.values)\n",
    "X_test_leaves = xgboost.apply(test_df.values)\n",
    "#Return the predicted leaf every tree for each sample.\n",
    "\n",
    "\n",
    "\n",
    "train_rows = X_train_leaves.shape[0]\n",
    "X_leaves = np.concatenate((X_train_leaves, X_val_leaves), axis=0)\n",
    "\n",
    "val_rows = X_leaves.shape[0]\n",
    "X_leaves = np.concatenate((X_leaves, X_test_leaves), axis=0)\n",
    "\n",
    "X_leaves = X_leaves.astype(np.int32)\n",
    "(rows, cols) = X_leaves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature OneHotEncoding\n",
    "xgbenc = OneHotEncoder()\n",
    "X_trans = xgbenc.fit_transform(X_leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoded feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded xgboost validation   auc: 0.97825\n",
      "Encoded xgboost test auc: 0.96541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\Python3.6\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_trans[:train_rows, :], train_y.values.ravel())\n",
    "\n",
    "y_pred_val_xgblr1 = lr.predict_proba(X_trans[train_rows:val_rows, :])\n",
    "y_pred_test_xgblr1 = lr.predict_proba(X_trans[val_rows:, :])\n",
    "verbose=0\n",
    "\n",
    "xgb_val_auc = roc_auc_score(np.array(val_y), np.array(y_pred_val_xgblr1)[:,1])\n",
    "xgb_test_auc = roc_auc_score(np.array(test_y), np.array(y_pred_test_xgblr1)[:,1])\n",
    "\n",
    "print('Encoded xgboost validation   auc: %.5f' % xgb_val_auc)\n",
    "print('Encoded xgboost test auc: %.5f' % xgb_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation logloss scores: 0.13155689423996186\n",
      "test logloss scores: 0.16697542751644873\n"
     ]
    }
   ],
   "source": [
    "logloss_val = log_loss(val_y, y_pred_val_xgblr1.astype('float64'))\n",
    "logloss_test = log_loss(test_y, y_pred_test_xgblr1.astype('float64'))\n",
    "\n",
    "print('validation logloss scores:', logloss_val)\n",
    "print('test logloss scores:', logloss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined feature validation LR AUC: 0.94127\n",
      "Combined feature test LR AUC: 0.90435\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "X_train_ext = hstack([X_trans[:train_rows, :], train_df])\n",
    "X_val_ext = hstack([X_trans[train_rows:val_rows, :], val_df])\n",
    "X_test_ext = hstack([X_trans[val_rows:, :], test_df])\n",
    "\n",
    "lr.fit(X_train_ext, train_y.values.ravel())\n",
    "\n",
    "y_pred_val_xgblr2 = lr.predict_proba(X_val_ext)\n",
    "y_pred_test_xgblr2 = lr.predict_proba(X_test_ext)\n",
    "\n",
    "xgb_val_auc = roc_auc_score(np.array(val_y).T[0], np.array(y_pred_val_xgblr2)[:,1])\n",
    "xgb_test_auc = roc_auc_score(np.array(test_y).T[0], np.array(y_pred_test_xgblr2)[:,1])\n",
    "\n",
    "print('Combined feature validation LR AUC: %.5f' % xgb_val_auc)\n",
    "print('Combined feature test LR AUC: %.5f' % xgb_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test logloss validation scores: 0.2075886060175333\n",
      "test logloss test scores: 0.2621061507190821\n"
     ]
    }
   ],
   "source": [
    "logloss_val = log_loss(val_y, y_pred_val_xgblr2.astype('float64'))\n",
    "logloss_test = log_loss(test_y, y_pred_test_xgblr2.astype('float64'))\n",
    "\n",
    "print('test logloss validation scores:', logloss_val)\n",
    "print('test logloss test scores:', logloss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation NDCG@5 scores: 0.9999999999999999\n",
      "test NDCG@5 scores: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "ndcg_val = ndcg_score(np.expand_dims(np.array(val_y).T[0], axis=0), np.expand_dims(np.array(y_pred_val_xgblr2)[:,1], axis=0), k=5)\n",
    "ndcg_test = ndcg_score(np.expand_dims(np.array(test_y).T[0], axis=0), np.expand_dims(np.array(y_pred_test_xgblr2)[:,1], axis=0), k=5)\n",
    "\n",
    "print('validation NDCG@5 scores:', ndcg_val)\n",
    "print('test NDCG@5 scores:', ndcg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
