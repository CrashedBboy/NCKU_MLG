{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package initialization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "\n",
    "DATASET = '../../data/extracted/LON-A/London_Attractions_Complete_Review.csv'\n",
    "OCCURENCE_THRESHOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "\n",
    "df = pd.read_csv(DATASET, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: \n",
      " ['Unnamed: 0', 'Unnamed: 0.1', 'iid', 'rid', 'rimages', 'rquote', 'rrate', 'rtime', 'uprofile', 'uage', 'ucity', 'ucountry', 'ugender', 'uhometown', 'uid_index', 'ulevel', 'uname_y', 'usince', 'ustate', 'ustyle', 'iattribute', 'ilocality', 'iname', 'ipopularity', 'ipost', 'irating', 'iregion', 'istreet', 'itag']\n",
      "\n",
      "Shape: \n",
      " (136978, 29)\n"
     ]
    }
   ],
   "source": [
    "# print dataset information\n",
    "\n",
    "print(\"Columns: \\n\", list(df.columns))\n",
    "print(\"\\nShape: \\n\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_time(df):\n",
    "    return df.sort_values(by=['rtime'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_occurrence(df, column, threshold):\n",
    "    return df.groupby(column).filter(lambda x: len(x) >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary(df):\n",
    "    df.loc[df['rrate'] != \"None\", 'rrate'] = 1.0\n",
    "    df.loc[df['rrate'] == \"None\", 'rrate'] = 0.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(dataframe):\n",
    "    \n",
    "    # sort by time (ascending order)\n",
    "    df = sort_by_time(dataframe)\n",
    "    \n",
    "    # retrieve needed columns\n",
    "    df = df[['uid_index', 'iid', 'rrate']]\n",
    "    \n",
    "    # convert ratings into binarys\n",
    "    df = convert_binary(df)\n",
    "    \n",
    "    df['rrate'] = pd.to_numeric(df['rrate'])\n",
    "    \n",
    "    # Retain users/items with at least five ratings only\n",
    "    df = filter_by_occurrence(df, 'iid', OCCURENCE_THRESHOLD)\n",
    "    df = filter_by_occurrence(df, 'uid_index', OCCURENCE_THRESHOLD)\n",
    "    \n",
    "    # split dataset into training set, validation set and test set\n",
    "    test_df = df.iloc[int(len(df)*0.8):]\n",
    "    train_validation_df = df.iloc[:int(len(df)*0.8)]\n",
    "    train_validation_df = train_validation_df.reindex(np.random.permutation(train_validation_df.index)) # shuffle\n",
    "    train_df = train_validation_df.iloc[:int(len(train_validation_df)*0.875)]\n",
    "    validation_df = train_validation_df.iloc[int(len(train_validation_df)*0.875):]\n",
    "    \n",
    "    return (train_df, validation_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size:  (95391, 3)\n",
      "validation set size:  (13628, 3)\n",
      "test set size:  (27255, 3)\n"
     ]
    }
   ],
   "source": [
    "# dataset preprocessing\n",
    "\n",
    "train_df, validation_df, test_df = data_preprocess(df)\n",
    "print(\"training set size: \", train_df.shape)\n",
    "print(\"validation set size: \", validation_df.shape)\n",
    "print(\"test set size: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "train_dataset = Dataset.load_from_df(train_df, reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = BaselineOnly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x1990c4245c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(algorithm, dataframe):\n",
    "    z = []\n",
    "    y = []\n",
    "    for i in range(len(dataframe)):\n",
    "        user = dataframe.iloc[i][0]\n",
    "        item = dataframe.iloc[i][1]\n",
    "        rating = dataframe.iloc[i][2]\n",
    "        prediction = algorithm.predict(user, item, r_ui=rating, verbose=False)\n",
    "        \n",
    "        if prediction.details['was_impossible'] == False:\n",
    "            z.append(prediction.est)\n",
    "            y.append(rating)\n",
    "    return (np.array(z, dtype=np.float32), np.array(y, dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_z, validation_y = predict(algorithm, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z, test_y = predict(algorithm, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_auc(z, y):\n",
    "    return metrics.roc_auc_score(y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation AUC:  0.9987355179145797\n",
      "test AUC:  0.9985223324593097\n"
     ]
    }
   ],
   "source": [
    "print(\"validation AUC: \", evaluate_auc(validation_z, validation_y))\n",
    "print(\"test AUC: \", evaluate_auc(test_z, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
