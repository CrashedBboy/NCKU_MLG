{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set-up\n",
    "import dependent packages and declare consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\lightfm\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "# package initialization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "\n",
    "DATASET = '../../data/extracted/LON-A/London_Attractions_Complete_Review.csv'\n",
    "# DATASET = '../../data/extracted/NYC-R/New_York_City_Restaurant_Complete_Review.csv'\n",
    "OCCURENCE_THRESHOLD = 5\n",
    "\n",
    "USER_FEATURES = ['ugender', 'ucity', 'ucountry', 'ulevel']\n",
    "ITEM_FEATURES = ['irating', 'itag']\n",
    "# ITEM_FEATURES = ['irating', 'itag', 'iprice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Dataset\n",
    "read dataset in csv format into pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "\n",
    "df = pd.read_csv(DATASET, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: \n",
      " ['Unnamed: 0', 'Unnamed: 0.1', 'iid', 'rid', 'rimages', 'rquote', 'rrate', 'rtime', 'uprofile', 'uage', 'ucity', 'ucountry', 'ugender', 'uhometown', 'uid_index', 'ulevel', 'uname_y', 'usince', 'ustate', 'ustyle', 'iattribute', 'ilocality', 'iname', 'ipopularity', 'ipost', 'irating', 'iregion', 'istreet', 'itag']\n",
      "\n",
      "Shape: \n",
      " (136978, 29)\n"
     ]
    }
   ],
   "source": [
    "# print dataset information\n",
    "\n",
    "print(\"Columns: \\n\", list(df.columns))\n",
    "print(\"\\nShape: \\n\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "* Retain users/items with at least five ratings only\n",
    "* Data splitting\n",
    "  - the latest 20% interactions (by time)\n",
    "  - Randomly split the remaining data into training (70%) and validation (10%) sets\n",
    "* Transform the ratings into binary implicit feedback as ground truth, indicating whether the user has interacted with the specific item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_time(df):\n",
    "    \n",
    "    # here we use 'rid' for sorting becaz it's auto incrementing\n",
    "    return df.sort_values(by=['rid'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_occurrence(df, column, threshold):\n",
    "    return df.groupby(column).filter(lambda x: len(x) >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary(df):\n",
    "    df.loc[df['rrate'] != \"None\", 'rrate'] = 1.0\n",
    "    df.loc[df['rrate'] == \"None\", 'rrate'] = 0.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(dataframe):\n",
    "    \n",
    "    # sort by time (ascending order)\n",
    "    df = sort_by_time(dataframe)\n",
    "    \n",
    "    # retrieve needed columns\n",
    "    df = df[['uid_index', 'iid', 'rrate'] + USER_FEATURES + ITEM_FEATURES]\n",
    "    \n",
    "    # convert ratings into binarys\n",
    "    df = convert_binary(df)\n",
    "    \n",
    "    df['rrate'] = pd.to_numeric(df['rrate'])\n",
    "    \n",
    "    # Retain users/items with at least five ratings only\n",
    "    df = filter_by_occurrence(df, 'iid', OCCURENCE_THRESHOLD)\n",
    "    df = filter_by_occurrence(df, 'uid_index', OCCURENCE_THRESHOLD)\n",
    "    \n",
    "    # split dataset into training set, validation set and test set\n",
    "    users = df.groupby('uid_index')\n",
    "    \n",
    "    test_df = pd.DataFrame()\n",
    "    train_validation_df = pd.DataFrame()\n",
    "    \n",
    "    # for each user, get its latest 20% rating as test set\n",
    "    for uid in users.size().to_dict().keys():\n",
    "        user = users.get_group(uid)\n",
    "        split_idx = int(len(user)*0.8)\n",
    "        test_df = test_df.append(user.iloc[split_idx:])\n",
    "        train_validation_df = train_validation_df.append(user.iloc[:split_idx])\n",
    "    \n",
    "    train_validation_df = train_validation_df.reindex(np.random.permutation(train_validation_df.index)) # shuffle\n",
    "    train_df = train_validation_df.iloc[:int(len(train_validation_df)*0.875)]\n",
    "    validation_df = train_validation_df.iloc[int(len(train_validation_df)*0.875):]\n",
    "    \n",
    "    return (train_df, validation_df, test_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size:  (90209, 9)\n",
      "validation set size:  (12887, 9)\n",
      "test set size:  (33178, 9)\n"
     ]
    }
   ],
   "source": [
    "# dataset preprocessing\n",
    "\n",
    "train_df, validation_df, test_df, whole_df = data_preprocess(df)\n",
    "print(\"training set size: \", train_df.shape)\n",
    "print(\"validation set size: \", validation_df.shape)\n",
    "print(\"test set size: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. load into LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all unique user ids\n",
    "def get_unique_uids(df):\n",
    "    return df['uid_index'].astype(str).unique()\n",
    "\n",
    "# get user ids of each row in pandas.DataFrame\n",
    "def get_uids(df):\n",
    "    return df['uid_index'].astype(str).values\n",
    "\n",
    "# get list of all unique user ids\n",
    "def get_unique_iids(df):\n",
    "    return df['iid'].astype(str).unique()\n",
    "\n",
    "# get item ids of each row in pandas.DataFrame\n",
    "def get_iids(df):\n",
    "    return df['iid'].astype(str).values\n",
    "\n",
    "# get list of all unique user features\n",
    "def get_unique_user_features(df):\n",
    "    sub_df = df[USER_FEATURES].astype(str)\n",
    "    return np.unique(sub_df.values.flatten())\n",
    "\n",
    "# get user features of each row in pandas.DataFrame\n",
    "def get_user_features(df):\n",
    "    sub_df = df[USER_FEATURES].astype(str)\n",
    "    return sub_df.values\n",
    "\n",
    "# get list of all unique item features\n",
    "def get_unique_item_features(df):\n",
    "    sub_df = df[ITEM_FEATURES].astype(str)\n",
    "    return np.unique(sub_df.values.flatten())\n",
    "\n",
    "# get item features of each row in pandas.DataFrame\n",
    "def get_item_features(df):\n",
    "    sub_df = df[ITEM_FEATURES].astype(str)\n",
    "    return sub_df.values\n",
    "\n",
    "# get list of tuples of user-item interactions\n",
    "def get_iteractions(df, rating=False):\n",
    "    \n",
    "    if rating:\n",
    "        columns = ['uid_index', 'iid', 'rrate']\n",
    "    else:\n",
    "        columns = ['uid_index', 'iid']\n",
    "        \n",
    "    df[['uid_index', 'iid']] = df[['uid_index', 'iid']].astype(str)\n",
    "        \n",
    "    rows = df[columns].values\n",
    "    return (tuple(r) for r in rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique users: 16255\n",
      "# unique items: 693\n",
      "# unique user features: 3132\n",
      "# unique item features: 628\n"
     ]
    }
   ],
   "source": [
    "print(\"# unique users:\", len(get_unique_uids(train_df)))\n",
    "print(\"# unique items:\", len(get_unique_iids(train_df)))\n",
    "print(\"# unique user features:\", len(get_unique_user_features(train_df)))\n",
    "print(\"# unique item features:\", len(get_unique_item_features(train_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tell dataset what dimension of latent/user/item matrix to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fit(\n",
    "    get_unique_uids(train_df),\n",
    "    get_unique_iids(train_df),\n",
    "    user_features = get_unique_user_features(train_df),\n",
    "    item_features = get_unique_item_features(train_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix shape -- Num users: 16255 x num_items 693.\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('Interaction matrix shape -- Num users: {} x num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build interaction matrix, which is the matrix storing user ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions, weights) = dataset.build_interactions(get_iteractions(train_df, rating=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<16255x693 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 90209 stored elements in COOrdinate format>\n",
      "<16255x693 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 90209 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(interactions))\n",
    "print(repr(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build user feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<16255x19387 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 76735 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "uid_ufeats = ((uid, list(ufeats)) for uid, ufeats in zip(get_uids(train_df), get_user_features(train_df)) )\n",
    "\n",
    "user_features = dataset.build_user_features(uid_ufeats)\n",
    "print(repr(user_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build item feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<693x1321 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 2079 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "iid_ifeats = ((iid, list(ifeats)) for iid, ifeats in zip(get_iids(train_df), get_item_features(train_df)) )\n",
    "\n",
    "item_features = dataset.build_item_features(iid_ifeats)\n",
    "print(repr(item_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model declaratoin & fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to tune model parameters, please check [lightfm.LightFM()](https://making.lyst.com/lightfm/docs/lightfm.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters  \n",
    "* no_components â€“ the dimensionality of the feature latent embeddings. Defaults to `10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts for model & training\n",
    "\n",
    "LOSS = 'logistic'\n",
    "LATENT=10\n",
    "\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=LATENT, loss=LOSS)\n",
    "model.fit(interactions, item_features=item_features, user_features=user_features, epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataframe):\n",
    "    df = dataframe[['uid_index', 'iid', 'rrate']]\n",
    "    z = []\n",
    "    y = []\n",
    "    for i in range(len(df)):\n",
    "        user = df.iloc[i][0]\n",
    "        item = df.iloc[i][1]\n",
    "        rating = df.iloc[i][2]\n",
    "        prediction = model.predict([user], [item])\n",
    "        \n",
    "        z.append(prediction[0])\n",
    "        y.append(rating)\n",
    "    return (np.array(z, dtype=np.float32), np.array(y, dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_z, validation_y = predict(model, validation_df)\n",
    "validation_z = (validation_z - np.min(validation_z)) / np.ptp(validation_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z, test_y = predict(model, test_df)\n",
    "test_z = (test_z - np.min(test_z)) / np.ptp(test_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_auc(z, y):\n",
    "    return metrics.roc_auc_score(y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation AUC: \", evaluate_auc(validation_z, validation_y))\n",
    "print(\"test AUC: \", evaluate_auc(test_z, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogLoss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume parameters z & y are ndarray\n",
    "def evaluate_logloss(z, y):\n",
    "    zz = np.ones((z.shape[0], 2))\n",
    "    zz[:, 0] -= z\n",
    "    zz[:, 1] = z\n",
    "    return metrics.log_loss(y, zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation LogLoss: \", evaluate_logloss(validation_z, validation_y))\n",
    "print(\"test LogLoss: \", evaluate_logloss(test_z, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDCG metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume parameters z & y are ndarray\n",
    "def evaluate_ndcg(z, y):\n",
    "    return metrics.ndcg_score(np.expand_dims(y, axis=0), np.expand_dims(z, axis=0), k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation NDCG@5: \", evaluate_ndcg(validation_z, validation_y))\n",
    "print(\"test NDCG@5: \", evaluate_ndcg(test_z, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = 'logistic'\n",
    "LATENT=10\n",
    "\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_latents(epoch=EPOCH, start=1, end=10, step=1):\n",
    "\n",
    "    history = []\n",
    "    for latent_n in range(start, end+step, step):\n",
    "        \n",
    "        print(\"Using latent size:\", latent_n)\n",
    "        model = LightFM(no_components=latent_n, loss=LOSS)\n",
    "        model.fit(interactions, item_features=item_features, user_features=user_features, epochs=epoch)\n",
    "        \n",
    "        validation_z, validation_y = predict(model, validation_df)\n",
    "        validation_z = (validation_z - np.min(validation_z)) / np.ptp(validation_z)\n",
    "        test_z, test_y = predict(model, test_df)\n",
    "        test_z = (test_z - np.min(test_z)) / np.ptp(test_z)\n",
    "        \n",
    "        history.append({\n",
    "            'epoch': epoch,\n",
    "            'latent': latent_n,\n",
    "            'val_auc': evaluate_auc(validation_z, validation_y),\n",
    "            'test_auc': evaluate_auc(test_z, test_y),\n",
    "            'val_logloss': evaluate_logloss(validation_z, validation_y),\n",
    "            'test_logloss': evaluate_logloss(test_z, test_y),\n",
    "            'val_ndcg': evaluate_ndcg(validation_z, validation_y),\n",
    "            'test_ndcg': evaluate_ndcg(test_z, test_y)\n",
    "        })\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using latent size: 1\n",
      "Using latent size: 2\n",
      "Using latent size: 3\n",
      "Using latent size: 4\n",
      "Using latent size: 5\n"
     ]
    }
   ],
   "source": [
    "history = train_latents(epoch=EPOCH, start=1, end=5, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| settings | validation AUC | validation LogLoss | validation NDCG@5 | testing AUC | testing LogLoss | testing NDCG@5 |\n",
      "|:-- | -- | -- | -- | -- | -- | -- |\n",
      "| latent_n=1 | 0.50097 | 1.46479 | 1.00000 | 0.49738 | 1.97449 | 0.27727 |\n",
      "| latent_n=2 | 0.50390 | 2.01784 | 1.00000 | 0.50333 | 3.12638 | 0.44685 |\n",
      "| latent_n=3 | 0.50260 | 2.12201 | 1.00000 | 0.50200 | 3.41549 | 0.27727 |\n",
      "| latent_n=4 | 0.50504 | 2.42503 | 1.00000 | 0.50610 | 3.90011 | 0.27727 |\n",
      "| latent_n=5 | 0.49486 | 2.61812 | 1.00000 | 0.48516 | 3.99912 | 0.44685 |\n"
     ]
    }
   ],
   "source": [
    "print(\"| settings | validation AUC | validation LogLoss | validation NDCG@5 | testing AUC | testing LogLoss | testing NDCG@5 |\")\n",
    "print(\"|:-- | -- | -- | -- | -- | -- | -- |\")\n",
    "for his in history:\n",
    "    print(\"| latent_n={} | {:.5f} | {:.5f} | {:.5f} | {:.5f} | {:.5f} | {:.5f} |\".format(\n",
    "        his['latent'],\n",
    "        his['val_auc'],\n",
    "        his['val_logloss'],\n",
    "        his['val_ndcg'],\n",
    "        his['test_auc'],\n",
    "        his['test_logloss'],\n",
    "        his['test_ndcg'],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LON-A dataset:  \n",
    "\n",
    "| settings | validation AUC | validation LogLoss | validation NDCG@5 | testing AUC | testing LogLoss | testing NDCG@5 |\n",
    "|:-- | -- | -- | -- | -- | -- | -- |\n",
    "| **latent_n=1*** | 0.50749 | 2.67413 | 0.66084 | 0.49727 | 2.15446 | 0.66084 |\n",
    "| latent_n=2 | 0.50484 | 2.79746 | 0.66084 | 0.49862 | 2.95496 | 0.44685 |\n",
    "| latent_n=3 | 0.50840 | 3.45294 | 0.66084 | 0.50411 | 3.46178 | 0.27727 |\n",
    "| latent_n=4 | 0.49764 | 3.70850 | 0.66084 | 0.49985 | 3.64026 | 0.27727 |\n",
    "| latent_n=5 | 0.48261 | 3.67404 | 0.66084 | 0.48091 | 3.81011 | 0.27727 |\n",
    "| latent_n=6 | 0.50135 | 4.22715 | 0.66084 | 0.49615 | 4.19156 | 0.27727 |\n",
    "| latent_n=7 | 0.50788 | 4.42946 | 0.66084 | 0.50081 | 4.46515 | 0.27727 |\n",
    "| latent_n=8 | 0.49772 | 4.40505 | 0.66084 | 0.48850 | 4.60153 | 0.27727 |\n",
    "| latent_n=9 | 0.50088 | 4.71791 | 0.66084 | 0.49938 | 4.48787 | 0.27727 |\n",
    "| latent_n=10 | 0.50002 | 4.66355 | 0.66084 | 0.49069 | 4.69170 | 0.27727 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
