{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set-up\n",
    "import dependent packages and declare consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package initialization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "\n",
    "DATASET = '../../data/extracted/LON-A/London_Attractions_Complete_Review.csv'\n",
    "OCCURENCE_THRESHOLD = 5\n",
    "\n",
    "USER_FEATURES = ['ugender', 'ucity', 'ucountry', 'ulevel']\n",
    "ITEM_FEATURES = ['irating', 'itag']\n",
    "# ITEM_FEATURES = ['iattribute', 'irating', 'itag', 'iprice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read Dataset\n",
    "read dataset in csv format into pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "\n",
    "df = pd.read_csv(DATASET, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: \n",
      " ['Unnamed: 0', 'Unnamed: 0.1', 'iid', 'rid', 'rimages', 'rquote', 'rrate', 'rtime', 'uprofile', 'uage', 'ucity', 'ucountry', 'ugender', 'uhometown', 'uid_index', 'ulevel', 'uname_y', 'usince', 'ustate', 'ustyle', 'iattribute', 'ilocality', 'iname', 'ipopularity', 'ipost', 'irating', 'iregion', 'istreet', 'itag']\n",
      "\n",
      "Shape: \n",
      " (136978, 29)\n"
     ]
    }
   ],
   "source": [
    "# print dataset information\n",
    "\n",
    "print(\"Columns: \\n\", list(df.columns))\n",
    "print(\"\\nShape: \\n\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Preprocessing\n",
    "\n",
    "* Retain users/items with at least five ratings only\n",
    "* Data splitting\n",
    "  - the latest 20% interactions (by time)\n",
    "  - Randomly split the remaining data into training (70%) and validation (10%) sets\n",
    "* Transform the ratings into binary implicit feedback as ground truth, indicating whether the user has interacted with the specific item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_time(df):\n",
    "    \n",
    "    # here we use 'rid' for sorting becaz it's auto incrementing\n",
    "    return df.sort_values(by=['rid'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_occurrence(df, column, threshold):\n",
    "    return df.groupby(column).filter(lambda x: len(x) >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary(df):\n",
    "    df.loc[df['rrate'] != \"None\", 'rrate'] = 1.0\n",
    "    df.loc[df['rrate'] == \"None\", 'rrate'] = 0.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(dataframe):\n",
    "    \n",
    "    # sort by time (ascending order)\n",
    "    df = sort_by_time(dataframe)\n",
    "    \n",
    "    # retrieve needed columns\n",
    "    df = df[['uid_index', 'iid', 'rrate'] + USER_FEATURES + ITEM_FEATURES]\n",
    "    \n",
    "    # convert ratings into binarys\n",
    "    df = convert_binary(df)\n",
    "    \n",
    "    df['rrate'] = pd.to_numeric(df['rrate'])\n",
    "    \n",
    "    # Retain users/items with at least five ratings only\n",
    "    df = filter_by_occurrence(df, 'iid', OCCURENCE_THRESHOLD)\n",
    "    df = filter_by_occurrence(df, 'uid_index', OCCURENCE_THRESHOLD)\n",
    "    \n",
    "    # split dataset into training set, validation set and test set\n",
    "    users = df.groupby('uid_index')\n",
    "    \n",
    "    test_df = pd.DataFrame()\n",
    "    train_validation_df = pd.DataFrame()\n",
    "    \n",
    "    # for each user, get its latest 20% rating as test set\n",
    "    for uid in users.size().to_dict().keys():\n",
    "        user = users.get_group(uid)\n",
    "        split_idx = int(len(user)*0.8)\n",
    "        test_df = test_df.append(user.iloc[split_idx:])\n",
    "        train_validation_df = train_validation_df.append(user.iloc[:split_idx])\n",
    "    \n",
    "    train_validation_df = train_validation_df.reindex(np.random.permutation(train_validation_df.index)) # shuffle\n",
    "    train_df = train_validation_df.iloc[:int(len(train_validation_df)*0.875)]\n",
    "    validation_df = train_validation_df.iloc[int(len(train_validation_df)*0.875):]\n",
    "    \n",
    "    return (train_df, validation_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size:  (90209, 9)\n",
      "validation set size:  (12887, 9)\n",
      "test set size:  (33178, 9)\n"
     ]
    }
   ],
   "source": [
    "# dataset preprocessing\n",
    "\n",
    "train_df, validation_df, test_df = data_preprocess(df)\n",
    "print(\"training set size: \", train_df.shape)\n",
    "print(\"validation set size: \", validation_df.shape)\n",
    "print(\"test set size: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. load into LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all unique user ids\n",
    "def get_unique_uids(df):\n",
    "    return df['uid_index'].astype(str).unique()\n",
    "\n",
    "# get user ids of each row in pandas.DataFrame\n",
    "def get_uids(df):\n",
    "    return df['uid_index'].astype(str).values\n",
    "\n",
    "# get list of all unique user ids\n",
    "def get_unique_iids(df):\n",
    "    return df['iid'].astype(str).unique()\n",
    "\n",
    "# get item ids of each row in pandas.DataFrame\n",
    "def get_iids(df):\n",
    "    return df['iid'].astype(str).values\n",
    "\n",
    "# get list of all unique user features\n",
    "def get_unique_user_features(df):\n",
    "    sub_df = df[USER_FEATURES].astype(str)\n",
    "    return np.unique(sub_df.values.flatten())\n",
    "\n",
    "# get user features of each row in pandas.DataFrame\n",
    "def get_user_features(df):\n",
    "    sub_df = df[USER_FEATURES].astype(str)\n",
    "    return sub_df.values\n",
    "\n",
    "# get list of all unique item features\n",
    "def get_unique_item_features(df):\n",
    "    sub_df = df[ITEM_FEATURES].astype(str)\n",
    "    return np.unique(sub_df.values.flatten())\n",
    "\n",
    "# get item features of each row in pandas.DataFrame\n",
    "def get_item_features(df):\n",
    "    sub_df = df[ITEM_FEATURES].astype(str)\n",
    "    return sub_df.values\n",
    "\n",
    "# get list of tuples of user-item interactions\n",
    "def get_iteractions(df, rating=False):\n",
    "    \n",
    "    if rating:\n",
    "        columns = ['uid_index', 'iid', 'rrate']\n",
    "    else:\n",
    "        columns = ['uid_index', 'iid']\n",
    "        \n",
    "    df[['uid_index', 'iid']] = df[['uid_index', 'iid']].astype(str)\n",
    "        \n",
    "    rows = df[columns].values\n",
    "    return (tuple(r) for r in rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique users: 16258\n",
      "# unique items: 692\n",
      "# unique user features: 3133\n",
      "# unique item features: 628\n"
     ]
    }
   ],
   "source": [
    "print(\"# unique users:\", len(get_unique_uids(train_df)))\n",
    "print(\"# unique items:\", len(get_unique_iids(train_df)))\n",
    "print(\"# unique user features:\", len(get_unique_user_features(train_df)))\n",
    "print(\"# unique item features:\", len(get_unique_item_features(train_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tell dataset what dimension of latent/user/item matrix to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fit(\n",
    "    get_unique_uids(train_df),\n",
    "    get_unique_iids(train_df),\n",
    "    user_features = get_unique_user_features(train_df),\n",
    "    item_features = get_unique_item_features(train_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix shape -- Num users: 16258 x num_items 692.\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('Interaction matrix shape -- Num users: {} x num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build interaction matrix, which is the matrix storing user ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions, weights) = dataset.build_interactions(get_iteractions(train_df, rating=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<16258x692 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 90209 stored elements in COOrdinate format>\n",
      "<16258x692 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 90209 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(interactions))\n",
    "print(repr(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build user feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<16258x19391 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 76750 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "uid_ufeats = ((uid, list(ufeats)) for uid, ufeats in zip(get_uids(train_df), get_user_features(train_df)) )\n",
    "\n",
    "user_features = dataset.build_user_features(uid_ufeats)\n",
    "print(repr(user_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build item feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<692x1320 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 2076 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "iid_ifeats = ((iid, list(ifeats)) for iid, ifeats in zip(get_iids(train_df), get_item_features(train_df)) )\n",
    "\n",
    "item_features = dataset.build_item_features(iid_ifeats)\n",
    "print(repr(item_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Model declaratoin & fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to tune model parameters, please check [lightfm.LightFM()](https://making.lyst.com/lightfm/docs/lightfm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts for model & training\n",
    "\n",
    "LOSS = 'logistic'\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1fbe74c0d88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss=LOSS)\n",
    "model.fit(interactions, item_features=item_features, user_features=user_features, epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataframe):\n",
    "    df = dataframe[['uid_index', 'iid', 'rrate']]\n",
    "    z = []\n",
    "    y = []\n",
    "    for i in range(len(df)):\n",
    "        user = df.iloc[i][0]\n",
    "        item = df.iloc[i][1]\n",
    "        rating = df.iloc[i][2]\n",
    "        prediction = model.predict([user], [item])\n",
    "        \n",
    "        z.append(prediction[0])\n",
    "        y.append(rating)\n",
    "    return (np.array(z, dtype=np.float32), np.array(y, dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid_index</th>\n",
       "      <th>iid</th>\n",
       "      <th>rrate</th>\n",
       "      <th>ugender</th>\n",
       "      <th>ucity</th>\n",
       "      <th>ucountry</th>\n",
       "      <th>ulevel</th>\n",
       "      <th>irating</th>\n",
       "      <th>itag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42135</th>\n",
       "      <td>13927</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Navan</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Level 4 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['clock tower', 'elizabeth tower', 'london eye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83291</th>\n",
       "      <td>4724</td>\n",
       "      <td>307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Level 4 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['swan lake', 'covent garden', 'backstage tour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75746</th>\n",
       "      <td>9162</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Level 5 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['winter wonderland', 'speakers corner', 'serp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47466</th>\n",
       "      <td>11667</td>\n",
       "      <td>221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Level 3 Contributor</td>\n",
       "      <td>3.5</td>\n",
       "      <td>['westminster palace', 'original palace', 'eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93362</th>\n",
       "      <td>13570</td>\n",
       "      <td>314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Derby</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Level 4 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['audrey hepburn', 'modern portraits', 'taylor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18760</th>\n",
       "      <td>9915</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Draper</td>\n",
       "      <td>United States</td>\n",
       "      <td>Level 6 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['street performers', 'market stalls', 'transp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>13299</td>\n",
       "      <td>626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Level 6 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['national theatre', 'london eye', 'street per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65120</th>\n",
       "      <td>15955</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Level 4 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['guided tour', 'westminster hall', 'local mp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26512</th>\n",
       "      <td>14286</td>\n",
       "      <td>317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Labuan Federal Territory</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Level 6 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['viewing platform', 'glass of champagne', 'th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127156</th>\n",
       "      <td>8685</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Level 5 Contributor</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['street performers', 'market stalls', 'transp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90209 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid_index  iid  rrate ugender                     ucity  \\\n",
       "42135      13927    4    0.0  female                     Navan   \n",
       "83291       4724  307    1.0     NaN                   England   \n",
       "75746       9162    9    1.0    male                Birmingham   \n",
       "47466      11667  221    1.0     NaN                       NaN   \n",
       "93362      13570  314    1.0  female                     Derby   \n",
       "...          ...  ...    ...     ...                       ...   \n",
       "18760       9915   24    1.0     NaN                    Draper   \n",
       "13238      13299  626    1.0    male                    London   \n",
       "65120      15955    7    1.0     NaN                Manchester   \n",
       "26512      14286  317    1.0     NaN  Labuan Federal Territory   \n",
       "127156      8685   24    0.0  female                 Singapore   \n",
       "\n",
       "              ucountry               ulevel  irating  \\\n",
       "42135          Ireland  Level 4 Contributor      4.5   \n",
       "83291   United Kingdom  Level 4 Contributor      4.5   \n",
       "75746   United Kingdom  Level 5 Contributor      4.5   \n",
       "47466              NaN  Level 3 Contributor      3.5   \n",
       "93362   United Kingdom  Level 4 Contributor      4.5   \n",
       "...                ...                  ...      ...   \n",
       "18760    United States  Level 6 Contributor      4.5   \n",
       "13238   United Kingdom  Level 6 Contributor      4.5   \n",
       "65120   United Kingdom  Level 4 Contributor      4.5   \n",
       "26512         Malaysia  Level 6 Contributor      4.5   \n",
       "127156       Singapore  Level 5 Contributor      4.5   \n",
       "\n",
       "                                                     itag  \n",
       "42135   ['clock tower', 'elizabeth tower', 'london eye...  \n",
       "83291   ['swan lake', 'covent garden', 'backstage tour...  \n",
       "75746   ['winter wonderland', 'speakers corner', 'serp...  \n",
       "47466   ['westminster palace', 'original palace', 'eng...  \n",
       "93362   ['audrey hepburn', 'modern portraits', 'taylor...  \n",
       "...                                                   ...  \n",
       "18760   ['street performers', 'market stalls', 'transp...  \n",
       "13238   ['national theatre', 'london eye', 'street per...  \n",
       "65120   ['guided tour', 'westminster hall', 'local mp'...  \n",
       "26512   ['viewing platform', 'glass of champagne', 'th...  \n",
       "127156  ['street performers', 'market stalls', 'transp...  \n",
       "\n",
       "[90209 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_z, validation_y = predict(model, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_z = (validation_z - np.min(validation_z)) / np.ptp(validation_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z, test_y = predict(model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z = (test_z - np.min(test_z)) / np.ptp(test_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_auc(z, y):\n",
    "    return metrics.roc_auc_score(y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation AUC:  0.5153114590031755\n",
      "test AUC:  0.5103611831544499\n"
     ]
    }
   ],
   "source": [
    "print(\"validation AUC: \", evaluate_auc(validation_z, validation_y))\n",
    "print(\"test AUC: \", evaluate_auc(test_z, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogLoss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume parameters z & y are ndarray\n",
    "def evaluate_logloss(z, y):\n",
    "    zz = np.ones((z.shape[0], 2))\n",
    "    zz[:, 0] -= z\n",
    "    zz[:, 1] = z\n",
    "    return metrics.log_loss(y, zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation LogLoss:  3.5314239833549883\n",
      "test LogLoss:  4.112882389394414\n"
     ]
    }
   ],
   "source": [
    "print(\"validation LogLoss: \", evaluate_logloss(validation_z, validation_y))\n",
    "print(\"test LogLoss: \", evaluate_logloss(test_z, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDCG metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume parameters z & y are ndarray\n",
    "def evaluate_ndcg(z, y):\n",
    "    return metrics.ndcg_score(np.expand_dims(y, axis=0), np.expand_dims(z, axis=0), k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation NDCG@5:  0.9999999999999999\n",
      "test NDCG@5:  0.44685352999185624\n"
     ]
    }
   ],
   "source": [
    "print(\"validation NDCG@5: \", evaluate_ndcg(validation_z, validation_y))\n",
    "print(\"test NDCG@5: \", evaluate_ndcg(test_z, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
