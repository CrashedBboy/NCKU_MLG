{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-Based Collaborative Filtering - Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set-up\n",
    "import dependent packages and declare consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package initialization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import BaselineOnly, KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "\n",
    "# DATASET = '../../data/extracted/LON-A/London_Attractions_Complete_Review.csv'\n",
    "DATASET = '../../data/extracted/NYC-R/New_York_City_Restaurant_Complete_Review.csv'\n",
    "OCCURENCE_THRESHOLD = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Dataset\n",
    "read dataset in csv format into pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "\n",
    "df = pd.read_csv(DATASET, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: \n",
      " ['Unnamed: 0', 'Unnamed: 0.1', 'rtime', 'rquote', 'iid', 'rrate', 'rid', 'uage', 'ucity', 'ucountry', 'ugender', 'uhometown', 'uid_index', 'ulevel', 'uname_y', 'usince', 'ustate', 'ustyle', 'iattribute', 'ilocality', 'iname', 'ipopularity', 'ipost', 'iprice', 'irating', 'iregion', 'istreet', 'itag']\n",
      "\n",
      "Shape: \n",
      " (129964, 28)\n"
     ]
    }
   ],
   "source": [
    "# print dataset information\n",
    "\n",
    "print(\"Columns: \\n\", list(df.columns))\n",
    "print(\"\\nShape: \\n\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "* Retain users/items with at least five ratings only\n",
    "* Data splitting\n",
    "  - the latest 20% interactions (by time)\n",
    "  - Randomly split the remaining data into training (70%) and validation (10%) sets\n",
    "* Transform the ratings into binary implicit feedback as ground truth, indicating whether the user has interacted with the specific item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_time(df):\n",
    "    \n",
    "    # here we use 'rid' for sorting becaz it's auto incrementing\n",
    "    return df.sort_values(by=['rid'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_occurrence(df, column, threshold):\n",
    "    return df.groupby(column).filter(lambda x: len(x) >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary(df):\n",
    "    df.loc[df['rrate'] != \"None\", 'rrate'] = 1.0\n",
    "    df.loc[df['rrate'] == \"None\", 'rrate'] = 0.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(dataframe):\n",
    "    \n",
    "    # sort by time (ascending order)\n",
    "    df = sort_by_time(dataframe)\n",
    "    \n",
    "    # retrieve needed columns\n",
    "    df = df[['uid_index', 'iid', 'rrate']]\n",
    "    \n",
    "    # convert ratings into binarys\n",
    "    df = convert_binary(df)\n",
    "    \n",
    "    df['rrate'] = pd.to_numeric(df['rrate'])\n",
    "    \n",
    "    # Retain users/items with at least five ratings only\n",
    "    df = filter_by_occurrence(df, 'iid', OCCURENCE_THRESHOLD)\n",
    "    df = filter_by_occurrence(df, 'uid_index', OCCURENCE_THRESHOLD)\n",
    "    \n",
    "    # split dataset into training set, validation set and test set\n",
    "    users = df.groupby('uid_index')\n",
    "    \n",
    "    test_df = pd.DataFrame()\n",
    "    train_validation_df = pd.DataFrame()\n",
    "    \n",
    "    # for each user, get its latest 20% rating as test set\n",
    "    for uid in users.size().to_dict().keys():\n",
    "        user = users.get_group(uid)\n",
    "        split_idx = int(len(user)*0.8)\n",
    "        test_df = test_df.append(user.iloc[split_idx:])\n",
    "        train_validation_df = train_validation_df.append(user.iloc[:split_idx])\n",
    "    \n",
    "    train_validation_df = train_validation_df.reindex(np.random.permutation(train_validation_df.index)) # shuffle\n",
    "    train_df = train_validation_df.iloc[:int(len(train_validation_df)*0.875)]\n",
    "    validation_df = train_validation_df.iloc[int(len(train_validation_df)*0.875):]\n",
    "    \n",
    "    return (train_df, validation_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size:  (80722, 3)\n",
      "validation set size:  (11532, 3)\n",
      "test set size:  (29517, 3)\n"
     ]
    }
   ],
   "source": [
    "# dataset preprocessing\n",
    "\n",
    "train_df, validation_df, test_df = data_preprocess(df)\n",
    "print(\"training set size: \", train_df.shape)\n",
    "print(\"validation set size: \", validation_df.shape)\n",
    "print(\"test set size: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load into Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "train_dataset = Dataset.load_from_df(train_df, reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model declaration & Fitting\n",
    "\n",
    "Collaborative Filtering - KNN:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = \\frac{\n",
    "\\sum\\limits_{j \\in N^k_u(i)} \\text{sim}(i, j) \\cdot r_{uj}}\n",
    "{\\sum\\limits_{j \\in N^k_u(i)} \\text{sim}(i, j)}\n",
    "\\end{equation}\n",
    "\n",
    "**Parameters**\n",
    "- `k` â€“ The max number of neighbors to take into account for aggregation, defaults to `40`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute consine similarity between items\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "\n",
    "K_MAX = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = KNNBasic(k=K_MAX, sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x24021dbc848>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(algorithm, dataframe):\n",
    "    z = []\n",
    "    y = []\n",
    "    for i in range(len(dataframe)):\n",
    "        user = dataframe.iloc[i][0]\n",
    "        item = dataframe.iloc[i][1]\n",
    "        rating = dataframe.iloc[i][2]\n",
    "        prediction = algorithm.predict(user, item, r_ui=rating, verbose=False)\n",
    "        \n",
    "        if prediction.details['was_impossible'] == False:\n",
    "            z.append(prediction.est)\n",
    "            y.append(rating)\n",
    "    return (np.array(z, dtype=np.float32), np.array(y, dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_z, validation_y = predict(algorithm, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z, test_y = predict(algorithm, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_auc(z, y):\n",
    "    return metrics.roc_auc_score(y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation AUC:  0.44881078535264324\n",
      "test AUC:  0.4852904654386654\n"
     ]
    }
   ],
   "source": [
    "print(\"validation AUC: \", evaluate_auc(validation_z, validation_y))\n",
    "print(\"test AUC: \", evaluate_auc(test_z, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogLoss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume parameters z & y are ndarray\n",
    "def evaluate_logloss(z, y):\n",
    "    zz = np.ones((z.shape[0], 2))\n",
    "    zz[:, 0] -= z\n",
    "    zz[:, 1] = z\n",
    "    return metrics.log_loss(y, zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation LogLoss:  2.6252315718365558\n",
      "test LogLoss:  2.1989300960122096\n"
     ]
    }
   ],
   "source": [
    "print(\"validation LogLoss: \", evaluate_logloss(validation_z, validation_y))\n",
    "print(\"test LogLoss: \", evaluate_logloss(test_z, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDCG metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume parameters z & y are ndarray\n",
    "def evaluate_ndcg(z, y):\n",
    "    return metrics.ndcg_score(np.expand_dims(y, axis=0), np.expand_dims(z, axis=0), k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation NDCG@5:  0.9061900191938579\n",
      "test NDCG@5:  0.9198132637649319\n"
     ]
    }
   ],
   "source": [
    "print(\"validation NDCG@5: \", evaluate_ndcg(validation_z, validation_y))\n",
    "print(\"test NDCG@5: \", evaluate_ndcg(test_z, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ks(start=3, end=20, step=1):\n",
    "\n",
    "    history = []\n",
    "    for k in range(start, end+step, step):\n",
    "        \n",
    "        print(\"Using K =\", k)\n",
    "        sim_options = {'name': 'cosine', 'user_based': False}\n",
    "        algorithm = KNNBasic(k=k, sim_options=sim_options)\n",
    "        \n",
    "        algorithm.fit(train_dataset)\n",
    "        validation_z, validation_y = predict(algorithm, validation_df)\n",
    "        test_z, test_y = predict(algorithm, test_df)\n",
    "        \n",
    "        history.append({\n",
    "            'k': k,\n",
    "            'val_auc': evaluate_auc(validation_z, validation_y),\n",
    "            'test_auc': evaluate_auc(test_z, test_y),\n",
    "            'val_logloss': evaluate_logloss(validation_z, validation_y),\n",
    "            'test_logloss': evaluate_logloss(test_z, test_y),\n",
    "            'val_ndcg': evaluate_ndcg(validation_z, validation_y),\n",
    "            'test_ndcg': evaluate_ndcg(test_z, test_y)\n",
    "        })\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using K = 21\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 22\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 23\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 24\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 25\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 26\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 27\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 28\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 29\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Using K = 30\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\surprise\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "history = train_ks(start=21, end=30, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| K | validation AUC | validation LogLoss | validation NDCG@5 | testing AUC | testing LogLoss | testing NDCG@5 |\n",
      "|:-- | -- | -- | -- | -- | -- | -- |\n",
      "| k=21 | 0.95310 | 0.17524 | 0.99751 | 0.97260 | 0.10368 | 0.99836 |\n",
      "| k=22 | 0.95310 | 0.17524 | 0.99751 | 0.97260 | 0.10368 | 0.99836 |\n",
      "| k=23 | 0.95342 | 0.17521 | 0.99751 | 0.97266 | 0.10367 | 0.99836 |\n",
      "| k=24 | 0.95342 | 0.17518 | 0.99751 | 0.97273 | 0.10366 | 0.99836 |\n",
      "| k=25 | 0.95373 | 0.17515 | 0.99751 | 0.97292 | 0.10363 | 0.99837 |\n",
      "| k=26 | 0.95372 | 0.17515 | 0.99751 | 0.97292 | 0.10364 | 0.99836 |\n",
      "| k=27 | 0.95372 | 0.17515 | 0.99751 | 0.97292 | 0.10364 | 0.99836 |\n",
      "| k=28 | 0.95372 | 0.17515 | 0.99751 | 0.97310 | 0.10361 | 0.99836 |\n",
      "| k=29 | 0.95372 | 0.17515 | 0.99751 | 0.97323 | 0.10360 | 0.99836 |\n",
      "| k=30 | 0.95372 | 0.17515 | 0.99751 | 0.97329 | 0.10359 | 0.99836 |\n"
     ]
    }
   ],
   "source": [
    "print(\"| K | validation AUC | validation LogLoss | validation NDCG@5 | testing AUC | testing LogLoss | testing NDCG@5 |\")\n",
    "print(\"|:-- | -- | -- | -- | -- | -- | -- |\")\n",
    "for his in history:\n",
    "    print(\"| k={} | {:.5f} | {:.5f} | {:.5f} | {:.5f} | {:.5f} | {:.5f} |\".format(\n",
    "        his['k'],\n",
    "        his['val_auc'],\n",
    "        his['val_logloss'],\n",
    "        his['val_ndcg'],\n",
    "        his['test_auc'],\n",
    "        his['test_logloss'],\n",
    "        his['test_ndcg'],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Results\n",
    "\n",
    "LON-A dataset:  \n",
    "\n",
    "| settings | validation AUC | validation LogLoss | validation NDCG@5 | testing AUC | testing LogLoss | testing NDCG@5 |\n",
    "|:-- | -- | -- | -- | -- | -- | -- |\n",
    "| **k=3*** | 0.49650 | 2.55242 | 0.92808 | 0.52433 | 2.12324 | 0.93968 |\n",
    "| k=4 | 0.48705 | 2.49657 | 0.92450 | 0.51455 | 2.13440 | 0.93399 |\n",
    "| k=5 | 0.47963 | 2.53492 | 0.92124 | 0.50672 | 2.17230 | 0.93057 |\n",
    "| k=6 | 0.46985 | 2.59390 | 0.91747 | 0.50322 | 2.18739 | 0.92855 |\n",
    "| k=7 | 0.46930 | 2.58139 | 0.91665 | 0.49993 | 2.20220 | 0.92678 |\n",
    "| k=8 | 0.46727 | 2.59588 | 0.91511 | 0.49648 | 2.19766 | 0.92571 |\n",
    "| k=9 | 0.46239 | 2.61721 | 0.91331 | 0.49478 | 2.19797 | 0.92488 |\n",
    "| k=10 | 0.46077 | 2.62906 | 0.91217 | 0.49323 | 2.19956 | 0.92423 |\n",
    "\n",
    "NYC-R dataset:  \n",
    "\n",
    "| settings | validation AUC | validation LogLoss | validation NDCG@5 | testing AUC | testing LogLoss | testing NDCG@5 |\n",
    "|:-- | -- | -- | -- | -- | -- | -- |\n",
    "| **k=3*** | 0.91139 | 0.16775 | 0.99766 | 0.95093 | 0.10484 | 0.99840 |\n",
    "| k=4 | 0.92084 | 0.17893 | 0.99748 | 0.95788 | 0.10601 | 0.99835 |\n",
    "| k=5 | 0.93513 | 0.17126 | 0.99769 | 0.96241 | 0.10535 | 0.99835 |\n",
    "| k=6 | 0.93385 | 0.17764 | 0.99750 | 0.96576 | 0.10466 | 0.99836 |\n",
    "| k=7 | 0.93859 | 0.17677 | 0.99751 | 0.96624 | 0.10684 | 0.99829 |\n",
    "| k=8 | 0.94221 | 0.17635 | 0.99751 | 0.96707 | 0.10665 | 0.99829 |\n",
    "| k=9 | 0.94542 | 0.17604 | 0.99751 | 0.96819 | 0.10649 | 0.99829 |\n",
    "| k=10 | 0.94623 | 0.17604 | 0.99751 | 0.96898 | 0.10650 | 0.99829 |\n",
    "| k=11 | 0.94784 | 0.17584 | 0.99751 | 0.96953 | 0.10640 | 0.99829 |\n",
    "| k=12 | 0.94862 | 0.17569 | 0.99751 | 0.97013 | 0.10631 | 0.99829 |\n",
    "| k=13 | 0.94973 | 0.17557 | 0.99751 | 0.97027 | 0.10628 | 0.99829 |\n",
    "| k=14 | 0.94973 | 0.17556 | 0.99751 | 0.97146 | 0.10383 | 0.99836 |\n",
    "| k=15 | 0.95043 | 0.17552 | 0.99751 | 0.97160 | 0.10380 | 0.99836 |\n",
    "| k=16 | 0.95043 | 0.17554 | 0.99751 | 0.97167 | 0.10379 | 0.99836 |\n",
    "| k=17 | 0.95112 | 0.17546 | 0.99751 | 0.97201 | 0.10375 | 0.99836 |\n",
    "| k=18 | 0.95180 | 0.17541 | 0.99751 | 0.97234 | 0.10371 | 0.99836 |\n",
    "| k=19 | 0.95213 | 0.17537 | 0.99751 | 0.97253 | 0.10369 | 0.99836 |\n",
    "| k=20 | 0.95278 | 0.17531 | 0.99751 | 0.97253 | 0.10369 | 0.99836 |\n",
    "| k=21 | 0.95310 | 0.17524 | 0.99751 | 0.97260 | 0.10368 | 0.99836 |\n",
    "| k=22 | 0.95310 | 0.17524 | 0.99751 | 0.97260 | 0.10368 | 0.99836 |\n",
    "| k=23 | 0.95342 | 0.17521 | 0.99751 | 0.97266 | 0.10367 | 0.99836 |\n",
    "| k=24 | 0.95342 | 0.17518 | 0.99751 | 0.97273 | 0.10366 | 0.99836 |\n",
    "| **k=25*** | 0.95373 | 0.17515 | 0.99751 | 0.97292 | 0.10363 | 0.99837 |\n",
    "| k=26 | 0.95372 | 0.17515 | 0.99751 | 0.97292 | 0.10364 | 0.99836 |\n",
    "| k=27 | 0.95372 | 0.17515 | 0.99751 | 0.97292 | 0.10364 | 0.99836 |\n",
    "| k=28 | 0.95372 | 0.17515 | 0.99751 | 0.97310 | 0.10361 | 0.99836 |\n",
    "| k=29 | 0.95372 | 0.17515 | 0.99751 | 0.97323 | 0.10360 | 0.99836 |\n",
    "| k=30 | 0.95372 | 0.17515 | 0.99751 | 0.97329 | 0.10359 | 0.99836 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
