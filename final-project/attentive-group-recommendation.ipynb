{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages initialization\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "# time\n",
    "# math\n",
    "# heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.data_dir = './data/CAMRa2011/'\n",
    "        self.embedding_size = 32\n",
    "#         self.epoch = 30\n",
    "        self.epoch = 1\n",
    "        self.num_negatives = 6\n",
    "        self.batch_size = 256\n",
    "        self.lr = 0.000005\n",
    "        self.drop_ratio = 0.2\n",
    "        self.topK = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAMRa2011Dataset(object):\n",
    "    \"\"\"CAMRa2011 dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_dir):\n",
    "        \n",
    "        self.pathes = {\n",
    "            'train': {\n",
    "                'user': dataset_dir + \"userRatingTrain.txt\",\n",
    "                'group': dataset_dir + \"groupRatingTrain.txt\"\n",
    "            },\n",
    "            'test': {\n",
    "                'user': dataset_dir + \"userRatingTest.txt\",\n",
    "                'user_negative': dataset_dir + \"userRatingNegative.txt\",\n",
    "                'group': dataset_dir + \"groupRatingTest.txt\",\n",
    "                'group_negative': dataset_dir + \"groupRatingNegative.txt\",\n",
    "            },\n",
    "            'group_user': dataset_dir + \"groupMember.txt\"\n",
    "        }\n",
    "        \n",
    "        # get the mapping of users and groups\n",
    "        # format: {gid: [uid, uid, ..], gid: [uid, uid, ..], ...}\n",
    "        self.group_members = self.get_group_user_mapping()\n",
    "        \n",
    "        # get interaction matrix from uid-iid training set\n",
    "        # train_user_matrix[uid, iid] = [1 | 0]\n",
    "        self.train_user_matrix = self.get_interaction_matrix(self.pathes['train']['user'])\n",
    "        \n",
    "        # format: [[uid, iid], [uid, iid], ...]\n",
    "        # only pairs of users & items have interactions would appear in the list\n",
    "        self.test_user_list = self.get_interaction_list(self.pathes['test']['user'])\n",
    "        \n",
    "        # format: [[uid, ...], [uid, ...], ...]\n",
    "        # test_user_negative_list & test_user_list follow the same order\n",
    "        # e.g. test_user_negative_list[0] is for test_user_list[0]\n",
    "        self.test_user_negative_list = self.get_negatives(self.pathes['test']['user_negative'])\n",
    "        \n",
    "        # get interaction matrix from gid-iid training set\n",
    "        self.train_group_matrix = self.get_interaction_matrix(self.pathes['train']['group'])\n",
    "\n",
    "        # pairs of group & item to be tested\n",
    "        self.test_group_list = self.get_interaction_list(self.pathes['test']['group'])\n",
    "\n",
    "        self.test_group_negative_list = self.get_negatives(self.pathes['test']['group_negative'])\n",
    "        \n",
    "    def get_user_dataloader(self, batch_size=256, shuffle=True):\n",
    "        \n",
    "        users, positives_negatives = self.get_train_instances(self.train_user_matrix)\n",
    "        dataset = TensorDataset(\n",
    "            torch.tensor(users, dtype=torch.float),\n",
    "            torch.tensor(positives_negatives, dtype=torch.float))\n",
    "        \n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        \n",
    "        return loader\n",
    "    \n",
    "    def get_group_dataloader(self, batch_size=256, shuffle=True):\n",
    "        \n",
    "        groups, positives_negatives = self.get_train_instances(self.train_group_matrix)\n",
    "        \n",
    "        dataset = TensorDataset(\n",
    "            torch.tensor(groups, dtype=torch.float),\n",
    "            torch.tensor(positives_negatives, dtype=torch.float))\n",
    "        \n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        \n",
    "        return loader\n",
    "    \n",
    "    # get number of groups, users and items\n",
    "    def get_sizes(self):\n",
    "        group_size = len(self.group_members)\n",
    "        (user_size, item_size) = self.train_user_matrix.shape\n",
    "        \n",
    "        return (group_size, user_size, item_size)\n",
    "        \n",
    "    def get_train_instances(self, interaction_matrix, num_negatives=6):\n",
    "        \n",
    "        users, positive_items, negative_items = [], [], []\n",
    "        \n",
    "        num_users, num_items = interaction_matrix.shape\n",
    "        \n",
    "        for (uid, iid) in interaction_matrix.keys():\n",
    "            \n",
    "            # positive instance\n",
    "            for _ in range(num_negatives):\n",
    "                \n",
    "                # positive instances\n",
    "                positive_items.append(iid)\n",
    "                \n",
    "                # negative instances ---> need to be fixed\n",
    "                negative_iid = np.random.randint(num_items+1)\n",
    "                while (uid, negative_iid) in interaction_matrix:\n",
    "                    negative_iid = np.random.randint(num_items+1) # re-generate an negative iid\n",
    "                negative_items.append(negative_iid)\n",
    "                \n",
    "                # users\n",
    "                users.append(uid)\n",
    "\n",
    "        positives_negatives = [[positive_iid, negative_iid] for positive_iid, negative_iid in zip(positive_items, negative_items)]\n",
    "        \n",
    "        return users, positives_negatives\n",
    "        \n",
    "        \n",
    "    def get_group_user_mapping(self):\n",
    "    \n",
    "        mapping = {}\n",
    "\n",
    "        # read mapping file\n",
    "        with open(self.pathes['group_user'], 'r') as file:\n",
    "\n",
    "            line = file.readline().strip()\n",
    "            while line != None and line != \"\":\n",
    "\n",
    "                # sample line format: [gid] [uid 1],[uid 2],[uid 3],[uid 4]\n",
    "                sequences = line.split(' ')\n",
    "                gid = int(sequences[0])\n",
    "                mapping[gid] = []\n",
    "                for uid in sequences[1].split(','):\n",
    "                    mapping[gid].append(int(uid))\n",
    "                line = file.readline().strip()\n",
    "\n",
    "        return mapping\n",
    "\n",
    "    # parse all interactions in dataset to 2D sparse matrix\n",
    "    def get_interaction_matrix(self, rating_file_path):\n",
    "\n",
    "        # get number of users and items\n",
    "        num_users, num_items = 0, 0\n",
    "        with open(rating_file_path, \"r\") as file:\n",
    "\n",
    "            line = file.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\" \")\n",
    "                uid, iid = int(arr[0]), int(arr[1])\n",
    "                num_users = max(num_users, uid)\n",
    "                num_items = max(num_items, iid)\n",
    "                line = file.readline()\n",
    "\n",
    "        # construct interaction matrix\n",
    "        # dok_matrix: Dictionary Of Keys based sparse matrix, an efficient structure for constructing sparse matrices incrementally.\n",
    "        matrix = sparse.dok_matrix((num_users + 1, num_items + 1), dtype=np.float32) # iid and uid starts from 1\n",
    "        with open(rating_file_path, \"r\") as file:\n",
    "            line = file.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\" \")\n",
    "                if len(arr) > 2:\n",
    "                    uid, iid, rating = int(arr[0]), int(arr[1]), int(arr[2])\n",
    "                    if (rating > 0):\n",
    "                        matrix[uid, iid] = 1.0\n",
    "                else:\n",
    "                    uid, iid = int(arr[0]), int(arr[1])\n",
    "                    matrix[uid, iid] = 1.0\n",
    "                line = file.readline()\n",
    "\n",
    "        return matrix\n",
    "    \n",
    "    # parse all interactions in dataset to list\n",
    "    def get_interaction_list(self, rating_file_path):\n",
    "\n",
    "        interaction_list = []\n",
    "        with open(rating_file_path, \"r\") as file:\n",
    "            line = file.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\" \")\n",
    "                uid, iid = int(arr[0]), int(arr[1])\n",
    "                interaction_list.append([uid, iid])\n",
    "                line = file.readline()\n",
    "\n",
    "        return interaction_list\n",
    "\n",
    "    # parse negative sample lists for pairs in test set\n",
    "    # negative samples: the items which never been interacted\n",
    "    # the order of returned sample lists must be paired with test list\n",
    "    def get_negatives(self, file_path):\n",
    "\n",
    "        negative_samples_list = []\n",
    "\n",
    "        with open(file_path, \"r\") as file:\n",
    "\n",
    "            line = file.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\" \")\n",
    "\n",
    "                negative_iids = []\n",
    "                for iid in arr[1:]:\n",
    "                    negative_iids.append(int(iid))\n",
    "\n",
    "                negative_samples_list.append(negative_iids)\n",
    "                line = file.readline()\n",
    "\n",
    "        return negative_samples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "\n",
    "a = [(1, 23), (12, 34)]\n",
    "\n",
    "na = torch.tensor(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CAMRa2011Dataset(config.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_group, num_user, num_item = dataset.get_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGREE Model (Attentive Group Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding networks\n",
    "\n",
    "class UserEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_users, embedding_dim):\n",
    "        super(UserEmbeddingLayer, self).__init__()\n",
    "        self.userEmbedding = nn.Embedding(num_users, embedding_dim)\n",
    "\n",
    "    def forward(self, uids):\n",
    "        user_embedded = self.userEmbedding(uids)\n",
    "        return user_embedded\n",
    "    \n",
    "class ItemEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim):\n",
    "        super(ItemEmbeddingLayer, self).__init__()\n",
    "        self.itemEmbedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, iids):\n",
    "        item_embedded = self.itemEmbedding(iids)\n",
    "        return item_embedded\n",
    "    \n",
    "class GroupEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_groups, embedding_dim):\n",
    "        super(GroupEmbeddingLayer, self).__init__()\n",
    "        self.groupEmbedding = nn.Embedding(num_groups, embedding_dim)\n",
    "\n",
    "    def forward(self, gids):\n",
    "        group_embedded = self.groupEmbedding(gids)\n",
    "        return group_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention network\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, drop_ratio=0):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(embedding_dim, 16)\n",
    "        self.linear2 = nn.Linear(16, 1)\n",
    "        self.dropout = nn.Dropout(p=drop_ratio)\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_ratio),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        weights = F.softmax(x.view(1, -1), dim=1)\n",
    "\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final layers of AGREE for prediction\n",
    "\n",
    "class PredictLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, drop_ratio=0):\n",
    "        super(PredictLayer, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(embedding_dim, 8)\n",
    "        self.dropout = nn.Dropout(p=drop_ratio)\n",
    "        self.linear2 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.linear2(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AGREE(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_groups, embedding_dim, group_member_mapping, drop_ratio):\n",
    "        super(AGREE, self).__init__()\n",
    "        \n",
    "        self.user_embedding = UserEmbeddingLayer(num_users, embedding_dim)\n",
    "        self.item_embedding = ItemEmbeddingLayer(num_items, embedding_dim)\n",
    "        self.group_embedding = GroupEmbeddingLayer(num_groups, embedding_dim)\n",
    "        self.attention = AttentionLayer(2 * embedding_dim, drop_ratio)\n",
    "        self.predict = PredictLayer(3 * embedding_dim, drop_ratio)\n",
    "        \n",
    "        self.group_members = group_member_mapping\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_groups = len(self.group_members)\n",
    "        \n",
    "        # initial model's parameters\n",
    "        for m in self.modules():\n",
    "            \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=1) # normal distribution\n",
    "            if isinstance(m, nn.Embedding):\n",
    "                nn.init.xavier_normal_(m.weight) # Glorot initialization\n",
    "\n",
    "    def forward(self, gids, uids, iids):\n",
    "        \n",
    "        # group prediction\n",
    "        if (gids is not None) and (uids is None):\n",
    "            output = self.group_forward(gids, iids)\n",
    "        # user prediction\n",
    "        else:\n",
    "            output = self.user_forward(uids, iids)\n",
    "            \n",
    "        return output\n",
    "\n",
    "    # group forwarding\n",
    "    def group_forward(self, gids, iids):\n",
    "        \n",
    "        # group_embeds = Variable(torch.Tensor())\n",
    "        group_embeddeds = torch.empty(0)\n",
    "        \n",
    "        # generate embedding vector for item\n",
    "        item_embeddeds = self.item_embedding(\n",
    "            iids.clone().type(torch.long).unsqueeze(dim=1)) # shape: (batch_size, 1, embedding_dim)\n",
    "        \n",
    "        # get attentive group embedding\n",
    "        for gid, iid in zip(gids, iids):\n",
    "            member_uids = self.group_members[gid.item()]\n",
    "            \n",
    "            # generate user embedding vector\n",
    "            member_embeddeds = self.user_embedding(\n",
    "                torch.tensor(member_uids, dtype=torch.long).unsqueeze(dim=1)) # shape: (batch_size, 1, embedding_dim)\n",
    "            \n",
    "            # generate item embedding vector\n",
    "            items = [iid.item() for _ in member_uids]\n",
    "            item_embeddeds = self.item_embedding(\n",
    "                torch.tensor(items, dtype=torch.long).unsqueeze(dim=1)) # shape: (batch_size, 1, embedding_dim)\n",
    "            \n",
    "            # get attentive weights for each user-item pair\n",
    "            user_item_embeddeds = torch.cat((member_embeddeds, item_embeddeds), dim=2) # shape: (num_member, 1, 2 * embedding_dim)\n",
    "            user_item_embeddeds = user_item_embeddeds.squeeze(dim=1) # shape: (num_member, 2 * embedding_dim)\n",
    "            attentive_weights = self.attention(user_item_embeddeds) # shape: (num_member, 1)\n",
    "            \n",
    "            # aggregation\n",
    "            member_embeddeds = member_embeddeds.squeeze(dim=1) # shape: (batch_size, embedding_dim)\n",
    "            aggregated_user_item_embeddeds = torch.matmul(attentive_weights.T, member_embeddeds) # shape: (1, embedding_dim)\n",
    "            \n",
    "            # generate group-item embedding vector\n",
    "            group_embedded = self.group_embedding(torch.tensor([[gid.item()]], dtype=torch.long)) # shape: (1, embedding_dim)\n",
    "            \n",
    "            # group embedding = user embedding aggregation + group preference embedding\n",
    "            aggregated_all_embedded = aggregated_user_item_embeddeds + group_embedded # shape: (1, embedding_dim)\n",
    "            \n",
    "            # append group embedding\n",
    "            group_embeddeds = torch.cat((group_embeddeds, group_embedded), dim=0) # shape: (batch_size, embedding_dim)\n",
    "            \n",
    "        # element-wise product: group-item interaction\n",
    "        interacted_embeddeds = torch.mul(group_embeddeds, item_embeddeds) # shape: (batch_size, embedding_dim)\n",
    "        \n",
    "        # pooling: [group x item, group, item]\n",
    "        pooled_embeddeds = torch.cat((interacted_embeddeds, group_embeddeds, item_embeddeds), dim=1) # shape: (batch_size, 3*embedding_dim)\n",
    "        \n",
    "        y = torch.sigmoid(self.predict(pooled_embeddeds))\n",
    "        return y\n",
    "\n",
    "    # user forwarding\n",
    "    def user_forward(self, uids, iids):\n",
    "        \n",
    "        # uids.shape: (batch_size, )\n",
    "        # iids.shape: (batch_size, )\n",
    "        \n",
    "        print(\"iids dtype\")\n",
    "        \n",
    "        # generate user embedding vectors\n",
    "        user_embeddeds = self.user_embedding(\n",
    "            uids.clone().type(torch.long).unsqueeze(dim=1)) # (batch_size, 1, embedding_dim)\n",
    "        \n",
    "        # generate item embedding vectors\n",
    "        item_embeddeds = self.item_embedding(\n",
    "            iids.clone().type(torch.long).unsqueeze(dim=1)) # (batch_size, 1, embedding_dim)\n",
    "        \n",
    "        # element-wise product: user-item interactions\n",
    "        interacted_embeddeds = torch.mul(user_embeddeds, item_embeddeds) # (batch_size, 1, embedding_dim)\n",
    "        \n",
    "        # pooling: [user x item, group, item]\n",
    "        pooled_embeddeds = torch.cat((interacted_embeddeds, user_embeddeds, item_embeddeds), dim=2) # (batch_size, 1, 3 * embedding_dim)\n",
    "        \n",
    "        # reshape x from (batch_size, 1, 3 * embedding_dim) to (batch_size, 3 * embedding_dim)\n",
    "        pooled_embeddeds = pooled_embeddeds.squeeze(dim=1)\n",
    "        \n",
    "        y = torch.sigmoid(self.predict(pooled_embeddeds))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training procedure\n",
    "def training(model, dataloader, epoch_id, config, input_type):\n",
    "    \n",
    "    # user trainning\n",
    "    learning_rate = config.lr\n",
    "\n",
    "    # lr decay: halve for every five epochs\n",
    "    for _ in range(0, epoch_id, 5):\n",
    "        learning_rate /= 2\n",
    "\n",
    "    # create optimizer\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print(\"Epoch {}, lr = {}, input_type = {}\".format(epoch_id, learning_rate, input_type))\n",
    "\n",
    "    losses = []\n",
    "    for batch_id, (uids, piids_niids) in enumerate(dataloader):\n",
    "        \n",
    "        print(batch_id, end=\" \")\n",
    "        \n",
    "        # Data Load\n",
    "        p_iids = piids_niids[:, 0]\n",
    "        n_iids = piids_niids[:, 1]\n",
    "        \n",
    "        # Forward\n",
    "        if input_type == 'user':\n",
    "            positive_predictions = model(None, uids, p_iids)\n",
    "            negative_predictions = model(None, uids, n_iids)\n",
    "        elif input_type == 'group':\n",
    "            positive_predictions = model(uids, None, p_iids)\n",
    "            negative_predictions = model(uids, None, n_iids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = torch.mean((positive_predictions - negative_predictions -1) **2)\n",
    "        \n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # record loss history\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGREE at embedding size: 32, epoch: 1, NDCG % HR: Top-5\n"
     ]
    }
   ],
   "source": [
    "agree = AGREE(num_user, num_item, num_group, config.embedding_size, dataset.group_members, config.drop_ratio)\n",
    "print(\"AGREE at embedding size: {}, epoch: {}, NDCG % HR: Top-{}\".format(config.embedding_size, config.epoch, config.topK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, lr = 5e-06, input_type = user\n",
      "0 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "1 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "2 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "3 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "4 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "5 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "6 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "7 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "8 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "9 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "10 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "11 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "12 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "13 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "14 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "15 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "16 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "17 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "18 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "19 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "20 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "21 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "22 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "23 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "24 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "25 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "26 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "27 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "28 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "29 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "30 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "31 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "32 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "33 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "34 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "35 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "pooled_embeddeds.shape: torch.Size([256, 1, 96])\n",
      "36 pooled_embeddeds.shape: torch.Size([256, 1, 96])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-39b558a211e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# train the model using user interactions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     user_loss = training(agree, dataset.get_user_dataloader(batch_size=config.batch_size, shuffle=True),\n\u001b[0m\u001b[0;32m      9\u001b[0m                  epoch, config, 'user')\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-95243f28d210>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(model, dataloader, epoch_id, config, input_type)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'user'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mpositive_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_iids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mnegative_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minput_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'group'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mpositive_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_iids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\attentive\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-1961b349b5fc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, gids, uids, iids)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# user prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-1961b349b5fc>\u001b[0m in \u001b[0;36muser_forward\u001b[1;34m(self, uids, iids)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# generate item embedding vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         item_embeddeds = self.item_embedding(\n\u001b[0m\u001b[0;32m     97\u001b[0m             iids.clone().type(torch.long).unsqueeze(dim=1)) # (batch_size, 1, embedding_dim)\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\attentive\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-754dcfc59f55>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, iids)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mitem_embedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mitem_embedded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\attentive\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\attentive\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\.conda\\envs\\attentive\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1722\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1724\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "for epoch in range(config.epoch):\n",
    "    \n",
    "    # set the model in train mode (some network like dropout will behave differently in train mode / evaluaiton mode)\n",
    "    agree.train(mode=True)\n",
    "    \n",
    "    # train the model using user interactions\n",
    "    user_loss = training(agree, dataset.get_user_dataloader(batch_size=config.batch_size, shuffle=True),\n",
    "                 epoch, config, 'user')\n",
    "    \n",
    "    history.append(user_loss)\n",
    "    \n",
    "    # train the model using group & members interactions\n",
    "    group_loss = training(agree, dataset.get_group_dataloader(batch_size=config.batch_size, shuffle=True),\n",
    "                 epoch, config, 'group')\n",
    "    \n",
    "    history.append(group_loss)\n",
    "    \n",
    "    print(\"Losses: {}, {}\".format(user_loss, group_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
